{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% Importação de bibliotecas\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Funções úteis\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def sigmoidArray(array):\n",
    "    return 1 / (1 + np.exp(-array))\n",
    "\n",
    "def lostFunction(realValue, calculatedValue):\n",
    "    return -((realValue * math.log10(calculatedValue)) + ((1-realValue) * math.log10(1-calculatedValue)))\n",
    "\n",
    "def lostFunctionArray(referenceVector, calculatedVector):\n",
    "    return -(np.dot(referenceVector, np.log10(calculatedVector).T) + np.dot((1-referenceVector), np.log10(1-calculatedVector).T))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Declaração de funções úteis que podem ser utilizadas universalmente.\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novos dados carregados com sucesso!\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rapha\\AppData\\Local\\Temp/ipykernel_14580/3325167118.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  TrainingSet = np.array([X, Y]).reshape(2,1)       # Conjunto de todos os pares ordenados (entrada, saída) dos exemplos de treinamento.                ##Formato: (2, 1)\n"
     ]
    }
   ],
   "source": [
    "# Variáveis\n",
    "m = int(4e2)                                            # Quantidade total de dados\n",
    "nx = int(2e2)                                           # Número de features por entrada\n",
    "\n",
    "# Geração aleatória dos dados para a simulação da aplicação da regressão logística com descida de gradiente\n",
    "X = np.random.rand(nx, m)                         # Entrada, podem ser imagens, sons, etc. Cada coluna representa 1 conjunto de dados de entrada.     ##Formato: (nx, m)\n",
    "Y = np.random.randint(0, 2, m).reshape(1,m)       # Saída(Entrada), pode ser uma classificação de animais, estilo musical, etc.                       ##Formato: (1, m)\n",
    "TrainingSet = np.array([X, Y]).reshape(2,1)       # Conjunto de todos os pares ordenados (entrada, saída) dos exemplos de treinamento.                ##Formato: (2, 1)\n",
    "\n",
    "# Inicialização dos parâmetros de ajuste da IA, parâmetros que sofrerão mudanças para tentar prever o resultado da saída\n",
    "w = np.zeros((nx, 1))                             # Parâmetros de ajuste dos dados de treinamento (iniciado em 0)                                     ##Formato: (nx,1)\n",
    "b = np.zeros((1,1))                               # Parâmetro de ajuste dos dados de treinamento (iniciado em 0)                                      ##Formato: (1,1)\n",
    "\n",
    "print(\"Novos dados carregados com sucesso!\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Geração de dados e variáveis relevantes para a simulação.\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrainingSet (conjunto de dados), formato (2, 1):\n",
      "[[array([[0.47382248, 0.62274892, 0.50987997, ..., 0.04231031, 0.99493997,\n",
      "          0.87941767],\n",
      "         [0.21889921, 0.62624716, 0.07080607, ..., 0.08023248, 0.95420818,\n",
      "          0.62398077],\n",
      "         [0.78460576, 0.56331153, 0.73656221, ..., 0.62226172, 0.23887389,\n",
      "          0.50372281],\n",
      "         ...,\n",
      "         [0.54701824, 0.10520484, 0.18248875, ..., 0.36222638, 0.93478279,\n",
      "          0.29627326],\n",
      "         [0.8397117 , 0.83635714, 0.90664147, ..., 0.44754792, 0.53292403,\n",
      "          0.2256433 ],\n",
      "         [0.43579684, 0.99092865, 0.56526454, ..., 0.33949684, 0.8639327 ,\n",
      "          0.09012665]])                                                   ]\n",
      " [array([[1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
      "          0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
      "          0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1,\n",
      "          0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "          1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
      "          1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
      "          0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
      "          1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0,\n",
      "          1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
      "          1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "          1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
      "          1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "          0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "          0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
      "          0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1,\n",
      "          0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
      "          0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0,\n",
      "          0, 0, 0, 1]])                                                    ]]\n",
      "\n",
      "X (Entrada), formato (200, 400):\n",
      "[[0.47382248 0.62274892 0.50987997 ... 0.04231031 0.99493997 0.87941767]\n",
      " [0.21889921 0.62624716 0.07080607 ... 0.08023248 0.95420818 0.62398077]\n",
      " [0.78460576 0.56331153 0.73656221 ... 0.62226172 0.23887389 0.50372281]\n",
      " ...\n",
      " [0.54701824 0.10520484 0.18248875 ... 0.36222638 0.93478279 0.29627326]\n",
      " [0.8397117  0.83635714 0.90664147 ... 0.44754792 0.53292403 0.2256433 ]\n",
      " [0.43579684 0.99092865 0.56526454 ... 0.33949684 0.8639327  0.09012665]]\n",
      "\n",
      "Y (Saída), formato (1, 400):\n",
      "[[1 1 1 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 0\n",
      "  0 0 0 0 1 0 0 1 0 1 0 1 1 0 0 0 1 1 0 1 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0\n",
      "  0 0 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 1 0 0 0 0 1 0\n",
      "  1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 0 1 1 1 0 0 1 0 0 0 1\n",
      "  1 0 1 0 0 0 0 1 1 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 1 1 0 0\n",
      "  1 1 0 1 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 0 0 1 0 1 1 1 0 1 0 1 0 0 0 1 1 0\n",
      "  0 0 1 1 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1\n",
      "  1 0 1 1 0 1 1 0 0 0 0 0 1 1 0 0 1 1 1 0 1 1 1 1 0 0 0 0 1 1 1 0 1 1 0 0\n",
      "  0 0 1 0 0 1 1 1 0 1 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 0 1 1 1 1 1 0 1\n",
      "  1 0 1 1 0 1 0 1 0 0 0 0 1 0 0 0 1 1 1 0 1 0 0 0 1 0 1 1 0 0 0 1 1 1 1 1\n",
      "  1 1 0 0 0 0 1 1 1 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1 0 1 0 0 1 0\n",
      "  0 0 0 1]]\n",
      "\n",
      "w (peso por entrada), formato (200, 1):\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "\n",
      "b (peso geral), formato (1, 1):\n",
      "[[0.]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"TrainingSet (conjunto de dados), formato {TrainingSet.shape}:\\n{TrainingSet}\"\n",
    "      f\"\\n\\nX (Entrada), formato {X.shape}:\\n{X}\"\n",
    "\n",
    "      f\"\\n\\nY (Saída), formato {Y.shape}:\\n{Y}\"\n",
    "      f\"\\n\\nw (peso por entrada), formato {w.shape}:\\n{w}\"\n",
    "      f\"\\n\\nb (peso geral), formato {b.shape}:\\n{b}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Visualização dos dados gerados.\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def accuracyCalc():\n",
    "    \"\"\"\n",
    "    Testa a regressão logística atual comparando os resultados obtidos com os corretos.\n",
    "\n",
    "    :returns: array = [Valores predizidos - formato(1, m), precisão das predições]\n",
    "    \"\"\"\n",
    "    prediction = np.zeros(m).reshape(1, m)\n",
    "    rights = 0\n",
    "\n",
    "    # Preenche o vetor de predição e calcula quantas vezes houve sucesso em prever o valor correto\n",
    "    Z = np.dot(w.T, X) + b\n",
    "    A = sigmoidArray(Z)\n",
    "    prediction = A\n",
    "\n",
    "    for i in range(m):\n",
    "        if (prediction[0][i] > 0.5) and (Y[0][i] > 0.5):\n",
    "            rights += 1\n",
    "        if (prediction[0][i] <= 0.5) and (Y[0][i] <= 0.5):\n",
    "            rights += 1\n",
    "\n",
    "    return [prediction, rights / m]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Função para calcular a precisão da IA\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def gradientDescentStep(input, output, weightVector, bValue, learningRate = 0.5):\n",
    "    # Funcional para parâmetros com formatos: x = (nx, m), y = (1, m), w = (nx, 1), b = (1, 1)\n",
    "    J = 0; db = 0; m = output.size; nx = weightVector.size; dw = np.zeros((nx, 1))\n",
    "\n",
    "    for i in range(m): # Calcular para cada amostra (i) do dataset que contém m amostras\n",
    "        # Variáveis úteis para cada amostra (i)\n",
    "        xi = input[:,i]                             # Entrada da amostra (i)\n",
    "        yi = output[0][i]                           # Saída da amostra (i)\n",
    "\n",
    "        # Cálculo da estimativa realizada pela regressão logística\n",
    "        zi = np.dot(weightVector.T, xi) + bValue    # z calculado para a amostra (i)\n",
    "        ai = sigmoid(zi)                            # Saída estimada, ou a da amostra (i)\n",
    "\n",
    "        # Calculo do erro da amostra (i) é adicionado ao contador para gerar a função de custo (o quão bem w e b estão ajustados com base em TODAS as amostras)\n",
    "        J += lostFunction(yi, ai)\n",
    "\n",
    "        # Cálculo das derivadas\n",
    "        dz = ai - yi\n",
    "        for d in range(nx):                         # Para cada um dos parâmetros w, calcula-se a derivada dele e adiciona-se ao contador\n",
    "            dw[d] += xi[d] * dz                     # xi*dz é o valor de dw(1, 2, ..., nx) da amostra (i)\n",
    "        db += dz                                    # dz é o valor de db da amostra (i)\n",
    "\n",
    "    # Cálculo dos valores totais (média de todas as amostras)\n",
    "\n",
    "    J  /= m                                         # Calculo da função de custo, o quão bem w e b estão ajustados para TODAS as amostras\n",
    "    dw /= m                                         # Calculo de cada uma das derivadas de w, para se dar um passo em direção ao mínimo global (melhor ajuste)\n",
    "    db /= m                                         # Calculo da derivada do parâmetro b, para se dar um passo em direção ao mínimo global (melhor ajuste)\n",
    "\n",
    "    # Passo do gradiente descendente para ajustar os parâmetros da IA em direção ao mínimo global\n",
    "    weightVector -= learningRate * dw\n",
    "    bValue -= learningRate * db\n",
    "\n",
    "    return J"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Implementação não vetorizada\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def gradientDescentStepVectorized(input, output, weightVector, bValue, learningRate = 0.5):\n",
    "    # Funcional para parâmetros com formatos: x = (nx, m), y = (1, m), w = (nx, 1), b = (1, 1)\n",
    "    m = output.size\n",
    "    Z = np.dot(weightVector.T, input) + bValue\n",
    "    A = sigmoidArray(Z)\n",
    "    J = np.sum(lostFunctionArray(output, A))/m\n",
    "    dZ = A - output\n",
    "    dW = np.dot(input, dZ.T) / m\n",
    "    dB = np.sum(dZ) / m\n",
    "\n",
    "    weightVector -= learningRate * dW\n",
    "    bValue -= learningRate * dB\n",
    "\n",
    "    return J"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Implementação vetorizada (livre dos 2 loops for)\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rapha\\AppData\\Local\\Temp/ipykernel_14580/3418056945.py:12: RuntimeWarning: divide by zero encountered in log10\n",
      "  return -(np.dot(referenceVector, np.log10(calculatedVector).T) + np.dot((1-referenceVector), np.log10(1-calculatedVector).T))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.2%\n",
      "3%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t84.5%\n",
      "7%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t86.2%\n",
      "10%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t84.8%\n",
      "13%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t86.8%\n",
      "17%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t85.0%\n",
      "20%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t87.2%\n",
      "23%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t85.2%\n",
      "27%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t87.5%\n",
      "30%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t85.2%\n",
      "33%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t87.5%\n",
      "37%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t85.5%\n",
      "40%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t87.5%\n",
      "43%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t85.8%\n",
      "47%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t87.5%\n",
      "50%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t85.8%\n",
      "53%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "57%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "60%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "63%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "67%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "70%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "73%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "77%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "80%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "83%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "87%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "90%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "93%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "97%\t- Erro cometido:\tnan%\t\t- Precisão medida:\t92.5%\n",
      "\n",
      "Tempo de execução: 13.402 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "steps = int(6e4)\n",
    "learningRate = 0.6\n",
    "\n",
    "aux = int(steps/30)\n",
    "tic = time.time_ns()\n",
    "for i in range(steps):\n",
    "    gradientDescentStepVectorized(X, Y, w, b, learningRate)\n",
    "    if i % aux == 0:\n",
    "        print(f\"{i/steps*100:.0f}%\\t- Erro cometido:\\t{gradientDescentStepVectorized(X, Y, w, b, learningRate)*100:.3f}%\"\n",
    "              f\"\\t\\t- Precisão medida:\\t{accuracyCalc()[1]*100:.1f}%\")\n",
    "    if i > int(steps/2):\n",
    "        learningRate = 0.25\n",
    "    if i > int(steps/1.3):\n",
    "        learningRate = 0.05\n",
    "\n",
    "toc = time.time_ns()\n",
    "\n",
    "print(f\"\\nTempo de execução: {(toc-tic)/1e9:.3f} s\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Realizando passos na descida de gradiente e verificando a melhora:\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão da IA: 74.8%\n",
      "\n",
      "w:\t\t\tb: [[9.98299781]]\n",
      "[[ 0.2135721 ]\n",
      " [-0.04439243]\n",
      " [-0.2583364 ]\n",
      " [-0.81551103]\n",
      " [-0.39861721]\n",
      " [-0.0117948 ]\n",
      " [ 0.14588146]\n",
      " [-0.24795919]\n",
      " [-1.53075368]\n",
      " [-1.00772658]\n",
      " [ 0.3555162 ]\n",
      " [-0.68382907]\n",
      " [-0.80410044]\n",
      " [ 0.20351784]\n",
      " [ 0.31936897]\n",
      " [-0.33535663]\n",
      " [-0.81209401]\n",
      " [-0.01948027]\n",
      " [-0.58661462]\n",
      " [-0.22823052]\n",
      " [-1.23506063]\n",
      " [ 0.0182734 ]\n",
      " [ 0.27208205]\n",
      " [-0.37725167]\n",
      " [-0.04013558]\n",
      " [ 0.61382127]\n",
      " [ 0.78103862]\n",
      " [-0.26718275]\n",
      " [-0.6280734 ]\n",
      " [ 0.42655452]\n",
      " [-0.53282597]\n",
      " [-0.11777138]\n",
      " [-0.32554949]\n",
      " [ 0.91733465]\n",
      " [-0.01733892]\n",
      " [ 0.07290484]\n",
      " [-0.64122185]\n",
      " [-0.00204296]\n",
      " [-0.48999312]\n",
      " [-0.07716762]\n",
      " [-0.73087102]\n",
      " [ 0.54605149]\n",
      " [-0.95776002]\n",
      " [-0.32200714]\n",
      " [-0.04003417]\n",
      " [-0.45998089]\n",
      " [-0.5531308 ]\n",
      " [-1.6036961 ]\n",
      " [ 1.21396864]\n",
      " [ 0.12113172]\n",
      " [ 0.17295907]\n",
      " [-0.12180049]\n",
      " [ 0.34251184]\n",
      " [ 0.59459549]\n",
      " [-0.07888498]\n",
      " [ 0.33134904]\n",
      " [ 0.32320074]\n",
      " [-0.60376306]\n",
      " [-0.02490157]\n",
      " [-0.59225256]\n",
      " [-0.12030459]\n",
      " [-0.46571043]\n",
      " [-0.00683861]\n",
      " [-0.71700832]\n",
      " [-0.09205898]\n",
      " [ 0.30878867]\n",
      " [ 1.11068834]\n",
      " [ 0.14653402]\n",
      " [ 0.07246816]\n",
      " [ 0.13474572]\n",
      " [ 0.51848   ]\n",
      " [ 0.09064321]\n",
      " [-0.82346249]\n",
      " [-0.47904578]\n",
      " [ 0.14917515]\n",
      " [-0.4256117 ]\n",
      " [-0.29872169]\n",
      " [-0.33486507]\n",
      " [-0.04233698]\n",
      " [-0.65747533]\n",
      " [ 0.65472278]\n",
      " [ 0.11826867]\n",
      " [-0.07462746]\n",
      " [ 0.44802598]\n",
      " [ 0.03980464]\n",
      " [ 0.10277393]\n",
      " [-0.88145216]\n",
      " [ 0.19051729]\n",
      " [ 0.56849727]\n",
      " [ 1.09937949]\n",
      " [-0.34166488]\n",
      " [-0.26022906]\n",
      " [ 0.55992135]\n",
      " [ 0.17681351]\n",
      " [-0.66775638]\n",
      " [-0.59382223]\n",
      " [-1.01782859]\n",
      " [ 0.02806758]\n",
      " [-0.55614586]\n",
      " [ 0.97628662]\n",
      " [ 0.46295685]\n",
      " [-0.83423544]\n",
      " [-0.69511103]\n",
      " [ 0.74261053]\n",
      " [ 0.3436639 ]\n",
      " [-0.20764542]\n",
      " [ 0.32897319]\n",
      " [-0.10622078]\n",
      " [-0.47100654]\n",
      " [ 0.33132263]\n",
      " [-0.12887332]\n",
      " [-0.47326821]\n",
      " [-0.33409788]\n",
      " [-1.33603268]\n",
      " [-1.09576018]\n",
      " [ 0.08871047]\n",
      " [-0.4945194 ]\n",
      " [-0.18304537]\n",
      " [ 0.13354219]\n",
      " [-0.3060619 ]\n",
      " [ 0.20548469]\n",
      " [ 0.14540908]\n",
      " [-0.27650174]\n",
      " [ 0.84341148]\n",
      " [ 0.22162702]\n",
      " [ 0.064758  ]\n",
      " [-0.47401625]\n",
      " [ 0.16300012]\n",
      " [-0.43915661]\n",
      " [ 0.23892218]\n",
      " [ 0.49023577]\n",
      " [ 0.1448174 ]\n",
      " [ 0.2611704 ]\n",
      " [ 1.1163736 ]\n",
      " [-0.21301197]\n",
      " [-0.26034383]\n",
      " [-0.17577575]\n",
      " [-0.87215312]\n",
      " [ 0.03913616]\n",
      " [ 0.21647676]\n",
      " [ 0.81500204]\n",
      " [ 0.08708077]\n",
      " [ 0.14193912]\n",
      " [-0.20616834]\n",
      " [-0.23974245]\n",
      " [ 0.08409564]\n",
      " [ 0.1604584 ]\n",
      " [ 0.32331292]\n",
      " [-0.39383102]\n",
      " [-0.803611  ]\n",
      " [ 0.560135  ]\n",
      " [-0.54118379]\n",
      " [-0.00825953]\n",
      " [ 0.10996871]\n",
      " [ 0.32458359]\n",
      " [ 0.50022173]\n",
      " [ 0.19744982]\n",
      " [-0.17957775]\n",
      " [-0.85251165]\n",
      " [-0.08704693]\n",
      " [ 0.00395625]\n",
      " [-0.37370283]\n",
      " [-0.16959471]\n",
      " [ 0.31905218]\n",
      " [-0.66885664]\n",
      " [-0.51448192]\n",
      " [-0.42237631]\n",
      " [-0.15761294]\n",
      " [-0.32914766]\n",
      " [ 0.34472632]\n",
      " [ 0.55234231]\n",
      " [ 0.33389951]\n",
      " [ 0.45047946]\n",
      " [ 0.02140914]\n",
      " [-0.58517771]\n",
      " [-0.37810632]\n",
      " [-0.54153899]\n",
      " [ 0.01077139]\n",
      " [ 0.03199495]\n",
      " [-0.01095455]\n",
      " [ 0.30384365]\n",
      " [ 0.50097599]\n",
      " [-0.17721767]\n",
      " [-0.26077218]\n",
      " [-0.14158179]\n",
      " [-0.15222763]\n",
      " [-0.11460835]\n",
      " [ 0.13300453]\n",
      " [ 0.55295737]\n",
      " [-0.02688792]\n",
      " [-0.23928849]\n",
      " [-0.04015233]\n",
      " [-0.39700331]\n",
      " [ 0.61624092]\n",
      " [-0.39792502]\n",
      " [-0.65235152]\n",
      " [-0.17393852]\n",
      " [-1.49839728]\n",
      " [-0.4049408 ]\n",
      " [-0.3293956 ]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precisão da IA: {accuracyCalc()[1]*100:.1f}%\\n\")\n",
    "print(f\"w:\\t\\t\\tb: {b}\\n{w}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Comparação diferença no treinamento\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão da IA: 75.0%\n",
      "\n",
      "w:\t\t\tb: [[5.83849371]]\n",
      "[[ 0.77194976]\n",
      " [ 0.1506866 ]\n",
      " [-1.09976433]\n",
      " [ 0.05835352]\n",
      " [-0.69477483]\n",
      " [-0.11400431]\n",
      " [-0.94244477]\n",
      " [ 0.11736175]\n",
      " [-0.70913038]\n",
      " [ 0.19773582]\n",
      " [-1.57835937]\n",
      " [ 0.46527052]\n",
      " [-1.31945808]\n",
      " [ 0.51577631]\n",
      " [-0.1198114 ]\n",
      " [-0.77661383]\n",
      " [-0.39518645]\n",
      " [-0.98007789]\n",
      " [-0.36687732]\n",
      " [-0.20311653]\n",
      " [-0.41302628]\n",
      " [ 0.15404697]\n",
      " [ 0.84526432]\n",
      " [ 0.1842165 ]\n",
      " [ 0.29155583]\n",
      " [-0.85238826]\n",
      " [ 0.11176619]\n",
      " [-0.00768103]\n",
      " [ 0.22992176]\n",
      " [ 1.11646298]\n",
      " [-0.58273188]\n",
      " [-0.00983843]\n",
      " [-0.18605715]\n",
      " [-0.53426968]\n",
      " [-0.17952407]\n",
      " [-0.96305473]\n",
      " [ 0.77256803]\n",
      " [-0.77573155]\n",
      " [-0.47045027]\n",
      " [ 0.13783302]\n",
      " [ 0.76762855]\n",
      " [ 0.37996003]\n",
      " [-1.04663539]\n",
      " [-0.16643575]\n",
      " [ 0.15913886]\n",
      " [ 0.23289993]\n",
      " [-0.16408245]\n",
      " [-1.12222097]\n",
      " [-0.28733666]\n",
      " [-0.5239992 ]\n",
      " [-0.34752518]\n",
      " [ 0.40779995]\n",
      " [ 0.19298278]\n",
      " [-0.85564686]\n",
      " [ 0.8256765 ]\n",
      " [-0.4382954 ]\n",
      " [-0.24044299]\n",
      " [ 0.36987032]\n",
      " [ 0.16079707]\n",
      " [ 1.32865377]\n",
      " [ 0.5831952 ]\n",
      " [ 1.0913743 ]\n",
      " [-0.08884485]\n",
      " [ 0.44507444]\n",
      " [-0.64966339]\n",
      " [ 0.03724374]\n",
      " [-0.08611471]\n",
      " [-0.59095063]\n",
      " [ 0.22996332]\n",
      " [ 0.04795471]\n",
      " [-0.13537467]\n",
      " [ 1.01825895]\n",
      " [-0.18662951]\n",
      " [ 0.21860039]\n",
      " [-0.03134322]\n",
      " [ 0.72800732]\n",
      " [-0.11442037]\n",
      " [ 0.59479224]\n",
      " [-0.4455608 ]\n",
      " [-0.4971862 ]\n",
      " [ 0.04864741]\n",
      " [-0.28479221]\n",
      " [ 0.6634533 ]\n",
      " [ 0.11296026]\n",
      " [-0.14270452]\n",
      " [-1.11087685]\n",
      " [-0.08409465]\n",
      " [ 0.29754455]\n",
      " [ 0.96106261]\n",
      " [ 0.12256151]\n",
      " [ 0.39103637]\n",
      " [-0.33428868]\n",
      " [ 0.00416872]\n",
      " [ 0.28323383]\n",
      " [-0.27135621]\n",
      " [-0.20172873]\n",
      " [ 0.05772946]\n",
      " [-0.39157639]\n",
      " [ 0.77762401]\n",
      " [ 1.14770328]\n",
      " [ 0.11185568]\n",
      " [-0.11551856]\n",
      " [-0.76372925]\n",
      " [ 0.05834456]\n",
      " [-0.2846033 ]\n",
      " [ 0.18984211]\n",
      " [ 0.0626964 ]\n",
      " [ 0.31101192]\n",
      " [ 0.1095523 ]\n",
      " [ 0.64088996]\n",
      " [ 0.4279828 ]\n",
      " [-0.74101399]\n",
      " [ 0.30246358]\n",
      " [ 0.21799018]\n",
      " [-0.21629681]\n",
      " [-0.50069296]\n",
      " [-0.15956821]\n",
      " [ 0.26100026]\n",
      " [-0.21202984]\n",
      " [-0.41492615]\n",
      " [ 0.3821301 ]\n",
      " [-0.11621315]\n",
      " [ 0.68508392]\n",
      " [-0.25527806]\n",
      " [-0.15543272]\n",
      " [ 0.38878475]\n",
      " [-0.09414668]\n",
      " [ 0.41099535]\n",
      " [-0.24389019]\n",
      " [-0.11623363]\n",
      " [ 0.47220961]\n",
      " [ 0.81019393]\n",
      " [ 0.40655048]\n",
      " [-0.14565291]\n",
      " [ 0.25594145]\n",
      " [-0.09637304]\n",
      " [-0.38683071]\n",
      " [-0.11385357]\n",
      " [-0.27187454]\n",
      " [-0.34035328]\n",
      " [-1.25028242]\n",
      " [-0.23240187]\n",
      " [-0.29132232]\n",
      " [ 0.34665021]\n",
      " [-0.39302703]\n",
      " [ 0.29854489]\n",
      " [ 0.96847298]\n",
      " [ 0.25212483]\n",
      " [-0.93694022]\n",
      " [-1.34380708]\n",
      " [ 0.93117698]\n",
      " [-0.29506957]\n",
      " [-0.2619257 ]\n",
      " [-0.03370504]\n",
      " [-0.64682821]\n",
      " [-0.41280165]\n",
      " [ 0.03334087]\n",
      " [-1.29867537]\n",
      " [-0.20300252]\n",
      " [-0.31281947]\n",
      " [-0.87794678]\n",
      " [ 0.59452414]\n",
      " [-0.3268934 ]\n",
      " [-0.93555497]\n",
      " [-0.19623276]\n",
      " [ 0.17207357]\n",
      " [-0.18278413]\n",
      " [-0.03565504]\n",
      " [ 1.03583618]\n",
      " [-0.27710339]\n",
      " [-0.57179811]\n",
      " [-0.34957652]\n",
      " [ 0.29466002]\n",
      " [-0.26354047]\n",
      " [-0.92977733]\n",
      " [-1.62893734]\n",
      " [ 0.7039288 ]\n",
      " [ 0.28941957]\n",
      " [-0.62086256]\n",
      " [ 0.55985972]\n",
      " [-0.02123013]\n",
      " [-0.13683766]\n",
      " [-0.31922946]\n",
      " [-0.60218836]\n",
      " [ 0.16185659]\n",
      " [ 1.09310898]\n",
      " [ 0.92540704]\n",
      " [-0.36879049]\n",
      " [-0.43090661]\n",
      " [-0.21319143]\n",
      " [ 0.77497692]\n",
      " [ 0.11572596]\n",
      " [-0.39440079]\n",
      " [-0.98376485]\n",
      " [ 0.3004783 ]\n",
      " [ 0.1545074 ]\n",
      " [ 0.05281982]\n",
      " [-0.94486701]\n",
      " [ 0.67852624]\n",
      " [ 0.39577681]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precisão da IA: {accuracyCalc()[1]*100:.1f}%\\n\")\n",
    "print(f\"w:\\t\\t\\tb: {b}\\n{w}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Comparação depois de treinar\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Tempo de execução não vetorizado    : 45209.99900 ms\n",
      "Tempo de execução codigo vetorizado : 48.00030 ms\n",
      "\n",
      "O código vetorizado é 941.9 vezes mais rápido em relação ao não vetorizado\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "stepNumber = 200\n",
    "\n",
    "# Versão não vetorizada\n",
    "tic = time.time_ns()\n",
    "for i in range(stepNumber):\n",
    "    gradientDescentStep(X, Y, w, b, 0.01)\n",
    "toc = time.time_ns()\n",
    "normalGradientTime = (toc - tic)/1e6 # tempo em milissegundos\n",
    "\n",
    "# Versão vetorizada\n",
    "tic = time.time_ns()\n",
    "for i in range(stepNumber):\n",
    "    gradientDescentStepVectorized(X, Y, w, b, 0.01)\n",
    "toc = time.time_ns()\n",
    "vectorizedGradientTime = (toc - tic)/1e6 # tempo em milissegundos\n",
    "\n",
    "print (f\"\\n\\nTempo de execução não vetorizado    : {normalGradientTime:.5f} ms\\n\"\n",
    "       f\"Tempo de execução codigo vetorizado : {vectorizedGradientTime:.5f} ms\\n\\n\"\n",
    "       f\"O código vetorizado é {normalGradientTime/vectorizedGradientTime:.1f} vezes mais rápido em relação ao não vetorizado\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Verificação da diferença de tempo entre a versão vetorizada vs não vetorizada da descida de gradiente na regressão logística\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisão da IA: 92.50%\n",
      "\n",
      "\n",
      "Comparação de valores:\n",
      "\n",
      "calc\t|\treal\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.09\t|\t1.00\t(X)\n",
      "\n",
      "0.96\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.11\t|\t0.00\t(Ok)\n",
      "\n",
      "0.20\t|\t0.00\t(Ok)\n",
      "\n",
      "0.66\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.15\t|\t0.00\t(Ok)\n",
      "\n",
      "0.92\t|\t1.00\t(Ok)\n",
      "\n",
      "0.29\t|\t0.00\t(Ok)\n",
      "\n",
      "0.17\t|\t0.00\t(Ok)\n",
      "\n",
      "0.97\t|\t1.00\t(Ok)\n",
      "\n",
      "0.06\t|\t0.00\t(Ok)\n",
      "\n",
      "0.04\t|\t0.00\t(Ok)\n",
      "\n",
      "0.50\t|\t0.00\t(X)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.78\t|\t1.00\t(Ok)\n",
      "\n",
      "0.24\t|\t0.00\t(Ok)\n",
      "\n",
      "0.27\t|\t0.00\t(Ok)\n",
      "\n",
      "0.36\t|\t0.00\t(Ok)\n",
      "\n",
      "0.38\t|\t0.00\t(Ok)\n",
      "\n",
      "0.86\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.44\t|\t1.00\t(X)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.92\t|\t1.00\t(Ok)\n",
      "\n",
      "0.11\t|\t0.00\t(Ok)\n",
      "\n",
      "0.65\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.08\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.44\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.01\t|\t0.00\t(Ok)\n",
      "\n",
      "0.84\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.73\t|\t1.00\t(Ok)\n",
      "\n",
      "0.18\t|\t0.00\t(Ok)\n",
      "\n",
      "0.75\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.20\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.74\t|\t1.00\t(Ok)\n",
      "\n",
      "0.67\t|\t0.00\t(X)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.95\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.97\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.85\t|\t1.00\t(Ok)\n",
      "\n",
      "0.81\t|\t1.00\t(Ok)\n",
      "\n",
      "0.96\t|\t1.00\t(Ok)\n",
      "\n",
      "0.72\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.47\t|\t1.00\t(X)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.88\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.02\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.94\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.09\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.82\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.82\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.52\t|\t0.00\t(X)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.31\t|\t0.00\t(Ok)\n",
      "\n",
      "0.08\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.75\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.71\t|\t1.00\t(Ok)\n",
      "\n",
      "0.93\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.42\t|\t0.00\t(Ok)\n",
      "\n",
      "0.29\t|\t0.00\t(Ok)\n",
      "\n",
      "0.45\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.91\t|\t1.00\t(Ok)\n",
      "\n",
      "0.59\t|\t0.00\t(X)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.10\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.69\t|\t1.00\t(Ok)\n",
      "\n",
      "0.95\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.68\t|\t1.00\t(Ok)\n",
      "\n",
      "0.85\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.57\t|\t0.00\t(X)\n",
      "\n",
      "0.13\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.22\t|\t0.00\t(Ok)\n",
      "\n",
      "0.13\t|\t0.00\t(Ok)\n",
      "\n",
      "0.55\t|\t1.00\t(Ok)\n",
      "\n",
      "0.76\t|\t1.00\t(Ok)\n",
      "\n",
      "0.99\t|\t1.00\t(Ok)\n",
      "\n",
      "0.52\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.84\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.27\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.27\t|\t0.00\t(Ok)\n",
      "\n",
      "0.86\t|\t1.00\t(Ok)\n",
      "\n",
      "0.75\t|\t1.00\t(Ok)\n",
      "\n",
      "0.28\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.20\t|\t0.00\t(Ok)\n",
      "\n",
      "0.15\t|\t0.00\t(Ok)\n",
      "\n",
      "0.25\t|\t0.00\t(Ok)\n",
      "\n",
      "0.98\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.39\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.24\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.99\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.01\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.08\t|\t0.00\t(Ok)\n",
      "\n",
      "0.34\t|\t0.00\t(Ok)\n",
      "\n",
      "0.93\t|\t0.00\t(X)\n",
      "\n",
      "0.15\t|\t0.00\t(Ok)\n",
      "\n",
      "0.45\t|\t0.00\t(Ok)\n",
      "\n",
      "0.01\t|\t0.00\t(Ok)\n",
      "\n",
      "0.81\t|\t1.00\t(Ok)\n",
      "\n",
      "0.85\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.97\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.04\t|\t0.00\t(Ok)\n",
      "\n",
      "0.99\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.94\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.24\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.87\t|\t1.00\t(Ok)\n",
      "\n",
      "0.55\t|\t0.00\t(X)\n",
      "\n",
      "0.99\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.08\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.69\t|\t1.00\t(Ok)\n",
      "\n",
      "0.20\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.54\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.86\t|\t1.00\t(Ok)\n",
      "\n",
      "0.60\t|\t1.00\t(Ok)\n",
      "\n",
      "0.40\t|\t1.00\t(X)\n",
      "\n",
      "0.78\t|\t0.00\t(X)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.01\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.33\t|\t0.00\t(Ok)\n",
      "\n",
      "0.33\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.55\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.30\t|\t0.00\t(Ok)\n",
      "\n",
      "0.28\t|\t0.00\t(Ok)\n",
      "\n",
      "0.36\t|\t1.00\t(X)\n",
      "\n",
      "0.61\t|\t1.00\t(Ok)\n",
      "\n",
      "0.83\t|\t1.00\t(Ok)\n",
      "\n",
      "0.21\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.56\t|\t1.00\t(Ok)\n",
      "\n",
      "0.95\t|\t1.00\t(Ok)\n",
      "\n",
      "0.05\t|\t0.00\t(Ok)\n",
      "\n",
      "0.89\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.79\t|\t0.00\t(X)\n",
      "\n",
      "0.38\t|\t1.00\t(X)\n",
      "\n",
      "0.97\t|\t1.00\t(Ok)\n",
      "\n",
      "0.44\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.72\t|\t1.00\t(Ok)\n",
      "\n",
      "0.92\t|\t1.00\t(Ok)\n",
      "\n",
      "0.68\t|\t0.00\t(X)\n",
      "\n",
      "0.03\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.93\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.16\t|\t1.00\t(X)\n",
      "\n",
      "0.87\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.69\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.32\t|\t1.00\t(X)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.71\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.98\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.60\t|\t0.00\t(X)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.68\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.23\t|\t0.00\t(Ok)\n",
      "\n",
      "0.02\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.75\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.46\t|\t1.00\t(X)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.63\t|\t0.00\t(X)\n",
      "\n",
      "0.99\t|\t1.00\t(Ok)\n",
      "\n",
      "0.67\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.61\t|\t1.00\t(Ok)\n",
      "\n",
      "0.93\t|\t1.00\t(Ok)\n",
      "\n",
      "0.55\t|\t0.00\t(X)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.18\t|\t0.00\t(Ok)\n",
      "\n",
      "0.11\t|\t0.00\t(Ok)\n",
      "\n",
      "0.88\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.74\t|\t1.00\t(Ok)\n",
      "\n",
      "0.92\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.23\t|\t0.00\t(Ok)\n",
      "\n",
      "0.73\t|\t1.00\t(Ok)\n",
      "\n",
      "0.08\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.49\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.04\t|\t0.00\t(Ok)\n",
      "\n",
      "0.72\t|\t0.00\t(X)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.39\t|\t0.00\t(Ok)\n",
      "\n",
      "0.20\t|\t0.00\t(Ok)\n",
      "\n",
      "0.66\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.62\t|\t0.00\t(X)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.09\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.96\t|\t1.00\t(Ok)\n",
      "\n",
      "0.53\t|\t1.00\t(Ok)\n",
      "\n",
      "0.70\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.88\t|\t1.00\t(Ok)\n",
      "\n",
      "0.22\t|\t0.00\t(Ok)\n",
      "\n",
      "0.81\t|\t1.00\t(Ok)\n",
      "\n",
      "0.54\t|\t1.00\t(Ok)\n",
      "\n",
      "0.38\t|\t0.00\t(Ok)\n",
      "\n",
      "0.69\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.96\t|\t1.00\t(Ok)\n",
      "\n",
      "0.04\t|\t0.00\t(Ok)\n",
      "\n",
      "0.09\t|\t0.00\t(Ok)\n",
      "\n",
      "0.06\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.66\t|\t1.00\t(Ok)\n",
      "\n",
      "0.22\t|\t0.00\t(Ok)\n",
      "\n",
      "0.12\t|\t0.00\t(Ok)\n",
      "\n",
      "0.55\t|\t0.00\t(X)\n",
      "\n",
      "0.76\t|\t1.00\t(Ok)\n",
      "\n",
      "0.71\t|\t1.00\t(Ok)\n",
      "\n",
      "0.96\t|\t1.00\t(Ok)\n",
      "\n",
      "0.27\t|\t0.00\t(Ok)\n",
      "\n",
      "0.45\t|\t1.00\t(X)\n",
      "\n",
      "0.92\t|\t0.00\t(X)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.24\t|\t0.00\t(Ok)\n",
      "\n",
      "0.62\t|\t1.00\t(Ok)\n",
      "\n",
      "0.33\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.65\t|\t1.00\t(Ok)\n",
      "\n",
      "0.29\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.81\t|\t1.00\t(Ok)\n",
      "\n",
      "0.98\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.29\t|\t1.00\t(X)\n",
      "\n",
      "0.76\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.02\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.74\t|\t1.00\t(Ok)\n",
      "\n",
      "0.93\t|\t1.00\t(Ok)\n",
      "\n",
      "0.66\t|\t1.00\t(Ok)\n",
      "\n",
      "0.01\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.82\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.73\t|\t1.00\t(Ok)\n",
      "\n",
      "0.51\t|\t0.00\t(X)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.47\t|\t1.00\t(X)\n",
      "\n",
      "0.26\t|\t0.00\t(Ok)\n",
      "\n",
      "0.99\t|\t1.00\t(Ok)\n",
      "\n",
      "0.53\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.43\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.91\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.74\t|\t1.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.65\t|\t1.00\t(Ok)\n",
      "\n",
      "0.03\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.00\t|\t0.00\t(Ok)\n",
      "\n",
      "0.12\t|\t0.00\t(Ok)\n",
      "\n",
      "1.00\t|\t1.00\t(Ok)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precisão da IA: {accuracyCalc()[1]*100:.2f}%\\n\")\n",
    "\n",
    "print(f\"\\nComparação de valores:\"\n",
    "      f\"\\n\\ncalc\\t|\\treal\")\n",
    "prediction = accuracyCalc()[0]\n",
    "for i in range(m):\n",
    "    print(f\"\\n{prediction[0][i]:.2f}\\t|\\t{Y[0][i]:.2f}\\t\", end=\"\")\n",
    "    printed = False\n",
    "    if (prediction[0][i] > 0.5) and (Y[0][i] > 0.5) and not printed:\n",
    "        print(\"(Ok)\")\n",
    "        printed = True\n",
    "    if (prediction[0][i] <= 0.5) and (Y[0][i] <= 0.5) and not printed:\n",
    "        print(\"(Ok)\")\n",
    "        printed = True\n",
    "    if not printed:\n",
    "        print(\"(X)\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Exibição de resultados\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}